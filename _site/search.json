[
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#reproducible-work---an-introduction",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#reproducible-work---an-introduction",
    "title": "An Introduction to Reproducible Research",
    "section": "Reproducible work - an introduction",
    "text": "Reproducible work - an introduction\nBefore we can discuss how we should structure our projects and manage our data, we need to first talk about reproducible research.\n\nWhat is reproducible work?\nAt its core, reproducible research is about being transparent in how to produce the results you report. In doing so, this allows anyone with your data and code to reproduce the work you have produced. This includes you, as there will be many times you need to check results, and a reproducible workflow will allow you to spot mistakes easily, and give you confidence that the code and data you use give the reported outcome every time they are run.\nReproducible research:\n\nContains relevant code, including which packages were used, and which programming language was used\nContains enough text, either via markdown or comments, to be able to understand the purpose of the code chunks and code document\n\nIdeally integrates code and results, along with text, into a single document (literate programming!)\n\nApplying good data quality control techniques to ensure that projects are self-contained so that all files and everything necessary to produce the output documents are easily accessible and accounted for\n\n\n\nWhy is it important?\nSimply put, mistakes happen. If your project is structured properly, you will have a code document that contains all of the relevant information, and it is easy to recreate the outcomes. Importantly, you will also have the necessary input files (and tracking of all their changes) stored within the project folder. That way, if you move computers, delete a document by accident, or hand over the project to another person, everything is neatly contained and can be reproduced without hassle.\n\n\nHow do I make reproducible work?\nThere are many different ways to make reproducible work. The information listed here should give you the foundations upon which you can build your own systems. However, the principles are the same and largely revolve around project structures, and dynamic documents that contain both the code and the results embedded in them. This way, updates to the code will automatically update results (including tables and figures), and you don’t need to worry about incorrectly copying the wrong version, or even retyping numbers in a table\nIn addition, a version control system like Git can prove to be an invaluable tool in making reproducible research. It is essential tracked changes for everything you do in a project: all the changes in your code, which files you produce, where you move files, the results your create … and the list goes on. We will talk through the basics of Git towards the end of this book, but if you would like a more in depth tutorial, you should read this fantastic resource by Jenny Bryan and co. It is aimed at R users, but much of it is generalizable. More resources are available at the end of the document."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#structuring-a-project",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#structuring-a-project",
    "title": "An Introduction to Reproducible Research",
    "section": "Structuring a project",
    "text": "Structuring a project\nThe first step in creating reproducible research is creating self-contained projects. Everything that goes in to, and comes out of, the project, should be contained within a single folder (directory). I would recommend that you create a folder called repos/ that your project folders live in, e.g. C:/User/owner/Documents/repos/proj/. This way your project folders are neatly separated from other files. Whilst we will discuss version control with Git later, I would suggest that you also routinely back up your project folder to separate drives (cloud and/or external hard drives), using a 3-2-1 system.\nNow you have set up your repos/ folder, it is time to create the project folder. This is the structure that I find works for me. You may want to find a variation on it that works for you, but the basic premise of keeping repositories self-contained should remain.\nC:/\n└── Documents/\n    └── repos/\n        └── proj/\n            ├── data/\n            ├── docs/\n            ├── figs/\n            ├── funs/\n            ├── out/\n            ├── cleaning.R\n            └── analysis.R\nAs you can see, the project repository contains separate directories that you can use to store different file types. Importantly, the analysis and cleaning files are stored in the project root, allowing easy use of relative paths over explicit paths e.g. read_csv(here('data', 'data_file.csv')) rather than read_csv('C:/Users/owner/Documents/Repos/my_project/data/data_file.csv'). The reason why relative paths are preferable is that they allow projects to be used by multiple people without the need to re-write code. If you use explicit paths and change computer, or the project is opened by another person, the code will break as they will not have the same directory structure as the computer that the code was created on.\n\nNote: the example above used an R package called here_here, calling the function here(). Similar solutions may exist for other languages, and you should try and find them for the language of your choice.\n\n\ndata/\nAn important idea is that you should treat your data as read-only. You and your team have likely worked hard to collect the data and it’s easy to make a changes along the way that you either forget about, or need to reverse. As most projects span a long time between the data collection and analysis stages, if that happens to you it will take a lot of work to figure out exactly which changes you are interested in reversing etc. To save yourself this hassle, and help make your work reproducible, once the data is collected it should not be edited; all the work should happen in your code, allowing it to be easily checked.\nIf you are following good data practices and treating your data as read-only, all your cleaning will happen within your code (create a cleaning file in your project e.g. proj-cleaning.R). However, if you do need to edit the files manually (and I strongly recommend against it as it makes it harder to reproduce as there isn’t a good way to track exactly what changes were made), you should create a save a new (separate) copy of the dataset (using file naming conventions) in your project directory (e.g. H:/repos/proj/2019-01-24_data-file.csv). Additionally, you should create a word document where you can list the changes you made with each new file. When we get to the section on Git, you will see how we can set it up to track all the changes within a project folder (including the create/deletion/movement of files!) so we don’t have to remember what changes we make. This means we can just have one copy of each document, and track the changes through time.\n\n\nOther subdirectories\n\ndocs/: this contains the output documents. For example, if you are using R Markdown to create a pdf via LaTeX, you could place them here.\nfuns/: this contains the functions you write and might want to reference. The idea is to create functions so that can give code a meaningful name. It also helps if you need to repeat a code chunk multiple times, especially if you need to edit it at some point, as you can just call the function rather than typing it out each time.\nout/: this contains files that are produced from the original data e.g. cleaned data files. You can then call them in your analysis scripts.\nfigs/: this contains figures that may be generated from your scripts.\n\nImportantly, if you follow the principle that your data/ files are read-only, all of the files in these directories (with the exception of funs/) should be reproducible and could be deleted at any time without concern of generating them again. In order to revert to previous figures and output versions, you will need to be able to track changes in your code. This is where a version control system like Git comes in, which we will discuss at the end."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#how-to-name-files-and-directories",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#how-to-name-files-and-directories",
    "title": "An Introduction to Reproducible Research",
    "section": "How to name files and directories",
    "text": "How to name files and directories\nHow you name files and directories may not seem like an important point, but it can cause quite a headache if you try and use code to automate processes, and at best, it just slows things down. To quote Aaron Quinlan, a bioinformatician, “a space in a filename is a space in one’s soul”.\nInstead try and use something like this:\n\nKISS (Keep It Simple Stupid): use simple and consistent file names\n\nIt needs to be machine readable\nIt needs to be human readable\nIt needs to order well in a directory\n\nNo special characters and no spaces!\nUse YYYY-MM-DD date format\nUse - to delimit words and _ to delimit sections\n\ni.e. 2019-01-19_my-data.csv\n\nLeft-pad numbers\n\ni.e. 01_my-data.csv vs 1_my-data.csv\nIf you don’t, file orders get messed up when you get to double-digits"
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#key-points",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#key-points",
    "title": "An Introduction to Reproducible Research",
    "section": "Key Points",
    "text": "Key Points\n\nUse a version control system such as Git to track changes in your code.\nData isn’t touched one collected:\n\nDo all data munging within your program i.e. no editing the excel spreadsheets!!!\nYou should have multiple backups on at least two different sets of servers/drives\n\nYour outputs should be reproducible from the code you have:\n\nMake sure this is the case by routinely clearing your programming environment and re-running the code in a clean environment to ensure your results aren’t contingent on ‘hidden’ packages/modules that were loaded erroneously\n\nNever set explicit file paths (e.g. setwd()) if you can avoid it\n\nTry and use a package that allows you to set relative paths e.g. here_here in R. This allows the project to be passed to someone else in its entirety and the code won’t break because they don’t have the same folder names and set up as you (also if you work on multiple computers/OS)\n\nFormat your filenames properly"
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#jupyter-notebooks",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#jupyter-notebooks",
    "title": "An Introduction to Reproducible Research",
    "section": "Jupyter notebooks",
    "text": "Jupyter notebooks\nThis section will give you a brief overview of what a Jupyter notebook is and how to use them, but if you would like a more detailed understanding, please read the official documentation. Jupyter Labs has now been released as a newer version of notebooks, giving you a full IDE (integrated development environment) and more control over the notebooks and working environment. This guide will not explore these features, as we are more interested in how to use the notebook.\n\nNote: throughout this section you can substitute the phrase “Jupyter notebooks” with “Jupyter Labs” if you would prefer to have a full IDE allowing you more control over the system.\n\nJupyter notebooks are run on Python, though additional things can be downloaded to allow you to use your programming language of choice. For an example of what you can do with Jupyter notebooks, click here, and here for a collection of neat and applied notebooks.\n\nInstalling Jupyter notebooks\nMac’s come shipped with a version of Python, but it is most likely outdated, and it doesn’t contain everything we want. In order to get running, I strongly recommend downloading the Anaconda distribution over other distributions, or even just directly from Python’s website. The instructions below will be enough to get you up and running with Jupyter notebooks in your language of choice.\n\nDownload the full Anaconda distribution i.e. not miniconda\n\nBe sure to choose Python 3.x, not Python 2.x, as it’s the newer version and is forwards-compatible.\nBe sure to only install for one user, not the whole system\nBe sure to select Add Anaconda to my PATH environment variable under Advanced Options\nBe sure to install Anaconda to the drive where your data lives. To do this you will need to manually edit the installation path within the Anaconda installer wizard, otherwise it will automatically end up in the C:\\ drive\n\nUse kernels to connect your programming language of choice with python and the notebook\n\nTo see how to get a particular language to work in Jupyter Notebooks, please click on the appropriate language:\n\nStata\nSAS\nR\n\n\n\n\n\nKernels\nA kernel is program that allows the notebook to connect with, and run, your code. Jupyter comes with the Python code pre-installed, but if you want to use a different language, you will need to download a specific kernel.\nBelow, the installation instructions are described for common languages used in epidemiology. To see a full list of kernels available for Jupyter, along with the appropriate documentation and installation instructions, follow this link.\n\nInstalling the Stata kernel\nThe instructions for installing the stata_kernel are based from the original documentation here. It should work with Stata 12 (I have tested it). If these instructions do not work for you, it may be that there has been an update to the kernel, at which point, please refer to the original documentation linked above.\nOpen a command prompt (Windows) / terminal (linux/mac) and type/copy-paste the following commands, pressing enter after each line\n\npip install stata_kernel\npython -m stata_kernel.install\n\nWindows-specific steps\nIn order to let stata_kernel talk to Stata, you need to link the Stata Automation library:\n\nIn the installation directory (most likely C:\\Program Files (x86)\\Stata12 or similar), right-click on the Stata executable, for example, StataSE.exe (this will just show as StataSE, but is listed as an application). Choose Create Shortcut. Placing it on the Desktop is fine.\nRight-click on the newly created Shortcut to StataSE.exe, choose Properties, and append/Register to the end of the Target field. So if the target is currently \"C:\\Program Files\\Stata12\\StataSE.exe\", change it to \"C:\\Program Files\\Stata12\\StataSE.exe\" /Register (note the space before /). Click OK.\nRight-click on the updated Shortcut to StataSE.exe; choose Run as administrator.\n\n\n\nInstalling the SAS kernel\n*This has not yet been tested here. The instructions for installing the sas_kernel are based from the original documentation here*\nOpen a command prompt (Windows) / terminal (linux/mac) and type/copy-paste the following commands, pressing enter after each line. First we need to install a dependency called saspy that helps the kernel connect SAS to python\n\npip install saspy\npip install sas_kernel\n\nYou should now see something like this.\nAvailable kernels:\npython3    /home/sas/anaconda3/lib/python3.5/site-packages/ipykernel/resources\nsas        /home/sas/.local/share/jupyter/kernels/sas\nNow verify that the SAS Executable is correct\n\nfind the sascfg.py file – it is currently located in the install location (see above) [install location]/site-packages/saspy/sascfg.py. To query pip for the location of the file, type pip show saspy. Failing that, this command will search the OS for the file location: find / -name sascfg.py\nedit the file with the correct path the SAS executable and include any options you wish it include in the SAS invocation. See examples in this file\n\n\n\nConnecting R with Jupyter\nIf you are hoping to make nice documents and reproducible work using R, I would highly recommend that you use the R Markdown or R Notebook through RStudio application instead. However, if you would prefer Jupyter, then please read on.\nIt is possible to download an R kernel, much like for Stata and SAS, but it can be a bit fickle, so a different approach is described below. It is important to note that with this method you are installing a fresh version of R, so you will not have access to the packages you have previously installed - you will need to reinstall them in this R environment, which could be done within a Jupyter notebook.\nOpen a command prompt (Windows) / terminal (Linux/Mac) and enter the following commands:\n\nconda install r-essentials r-igraph\nRscript -e 'install.packages(\"languageserver\")'\n\nIf you would rather install an R kernel than a fresh install of R within the Anaconda distribution, you can follow the instructions here. The advantage of this is that it allows the notebook to access previously installed packages as they are not running off a fresh version of R."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#using-jupyter-notebooks",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#using-jupyter-notebooks",
    "title": "An Introduction to Reproducible Research",
    "section": "Using Jupyter notebooks",
    "text": "Using Jupyter notebooks\nNow you have set up Jupyter to run with the programming language of your choice, we should start using it. How you do that is detailed in this section.\n\nCreating a notebook\nYou can either open up the Anaconda navigator and then Jupyter notebooks, or open Jupyter notebooks directly. Once open, navigate to the directory you would like to create the notebook in (If you are using a version control system like Git, then you should be within the project’s repository)\nSelect the New button in the top right corner, and then select the language you would like to program in (this assumes that you have downloaded an appropriate kernel if you would like to use a language other than Python)\n\n\nRunning a Jupyter notebook\nNow you have the notebook open in your chosen language, it’s time to start doing some data exploration and analysis. Here, we’ll cover some basic commands that will get you started, but to fully leverage the power of the notebook, you should read the Jupyter documentation, along with the documentation of your preferred kernel, particularly sections relating to magic commands (which are language-specific).\nWhen you are writing in a cell (‘Edit’ mode), you can use these commands:\n\n\n\n\n\n\n\nKeyboard shortcut\n\n\n\n\n\nShift + Enter\nExecutes the current cell and enters you into the next one\n\n\nCtrl/Cmd + Enter\nExecutes the current cell, but does not enter you into the next one\n\n\nEsc\nThis exits ‘Edit’ mode without executing the cells\n\n\nTab\nCode completion or indent\n\n\n\nIf you are not in ‘Edit’ mode (‘Command’ mode), and therefore at least one cell is selected, you can use these commands:\n\n\n\n\n\n\n\nKeyboard shortcut\n\n\n\n\n\nCtrl/Cmd + a\nAdd an empty cell above your current cell\n\n\nCtrl/Cmd + b\nAdd an empty cell below your current cell\n\n\ndd\nDelete the selected cell\n\n\nCtrl/Cmd + m\nChange the cell type to ‘Markdown’ so you can add text\n\n\nCtrl/Cmd + y\nChange the cell type to ‘Code’ so you can add code\n\n\nEnter\nEnter ‘Edit’ mode\n\n\n\n\n\nCustomizing Jupyter notebook’s UI\nThe following section is not essential and can be ignored if you want to keep things as simple as possible.\nBecause I do not like the In[] Out[] text showing in documents, along with centering plots/figures, I have customized the Jupyter notebook settings. If you would like to do the same, this section should help you. It is not necessary, but I feel that it gives cleaner documents (including pdf documents via LaTeX). If you do this, it is essential that you routinely restart the kernel to run everything again in a fresh environment as it is incredibly easy to run code blocks out of order and forget how this changes the output and introduces hidden packages.\nIf you would like to customize the look of the notebook, jupyterthemes is a great package that can be installed. I have also edited the custom.css file (C:\\Users\\owner\\.jupyter\\custom\\), adding display: None; under the section\ndiv.prompt,\n .prompt {\nso that it now reads\ndiv.prompt,\n .prompt {\n font-family: monospace, monospace;\n font-size: 9pt !important;\n font-weight: normal;\n display: None;\n .\n .\n .\n}\nThis removes the In[] Out[] text. To centre the output of tables/figures, add\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\nto the custom.css file, right after the .prompt {..} section.\nTo enable soft wrapping in the notebook, you need to edit the notebook.json file (C:\\Users\\owner\\.jupyter\\nbconfig\\). If it does not exist, you need to create it. Once open, add\n{\n  \"MarkdownCell\": {\n    \"cm_config\": {\n      \"lineWrapping\": true\n    }\n  },\n  \"CodeCell\": {\n    \"cm_config\": {\n      \"lineWrapping\": true\n    }\n  }\n}\nbefore restarting Jupyter."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#output-documents",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#output-documents",
    "title": "An Introduction to Reproducible Research",
    "section": "Output documents",
    "text": "Output documents\nWe’ve covered a lot of information up until now about setting up your projects and your code, but a big part of reproducible research is the creation of nice-looking and transparent documents. The reason we’ve gone to such effort to install Jupyter notebooks and connect them with our language of choice is that not only do they allow for excellent data exploration, but they also make documents that look professional.\nIn scientific articles, whilst it’s not essential, LaTeX is a nice touch, and Jupyter can give you a LaTeX formatted pdf documents. To do this, you will first need to install LaTeX. If you are on Windows, I would recommend the MiKTeX distribution, and if you use a Mac, then I would recommend the MacTeX distribution. You will also need the “swiss-army knife” of file conversion, pandoc. Pandoc is not needed for creating LaTeX-formatted pdfs, but if you have documents with unsupported characters and you need to use a different pdf-engine you’ll need to use pandoc.\nDuring the installation process, LaTeX should have been added automatically to the PATH. To test this, enter pdflatex into a command line/terminal. If you get the output This is pdfTeX ... then you are good to go. If not, please add the executable to the PATH. In Windows you do this by navigating to Environment Variables from the Windows key and editing the PATH in User Variables. In Mac, you should open the terminal and enter touch ~/.bash_profile; open ~/.bash_profile, which opens (or creates if missing) the file that stores your PATH. From here, type export PATH=\"path-to-latex-executable:$PATH\" to add the executable to the path. Now save and exit the text editor, run source ~/.bash_profile in your terminal, and you’re good to go. The executable location can be found by opening the MiKTeX/MacTeX console and looking at the bin directory under settings. For me, on a Windows computer where I don’t have administrator privileges it reads C:\\Users\\owner\\AppData\\Local\\Programs\\MiKTeX 2.9\\miktex/bin/x64. If you are still having issues, please consult this document.\nNow you’re ready to create a LaTeX-formatted pdf document. All you need to do is click File -> Download as -> PDF via LaTeX (.pdf).\nUnfortunately, when creating pdf documents, code is not hard wrapped. This means that if you have a very long line of code (> 80 characters), it will run out of the formatted area, and at worst, off the page. At present, I do not know a way to force Jupyter notebooks to wrap the output automatically, so instead you have to write clean code and start new lines using , and \\n if it’s too long.\nIf you would rather not produce a pdf via LaTeX, instead wanting an arguably more readable output, you could create an html file. This is done in the same manner as pdf documents."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#set-up",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#set-up",
    "title": "An Introduction to Reproducible Research",
    "section": "Set up",
    "text": "Set up\nThere are many ways to get Git running on your computer. Depending on your OS and the version you have, Git may come pre-installed on your computer. However, it is a good idea to update it to the latest version, so I’d recommend you follow the steps below anyway.\n\nWindows\n\nInstall Git for Windows\n\nThis gives you Git Bash, which is a much nicer way of interfacing with Git than the command line.\nNote: when asked about “Adjusting your PATH environment”, be sure to select “Git from the command line and also from 3rd-party software”. The other default options should be fine. For more details about the installation settings, please click here\n\nOpen up Git Bash and enter where git. Open up the command line and enter where git. Depending on whether you have administrator privileges, the outputs should look something like this, respectively\n\nwhich git : /mingw64/bin/git\nwhere git : C:\\Users\\owner\\AppData\\Local\\Programs\\git\\bin\\git.exe (User privileges)\n\nwhere git : C:\\Program Files\\git\\bin\\git.exe (administrator privileges)\n\n\n\nIf you see cmd instead of bin, then you need to edit the PATH in your environment variables, as above. You can do this by typing environment variables into the Start box and scrolling to the PATH section of User/System variables (depending on whether you have administrator privileges), and changing cmd to bin in the git.exe path.\n\n\n\n\nMac\nThere are more (workable) ways to install Git on OSX than on Windows, but I think this is the best option as it gives you a great package manager for the future.\n\nOpen the terminal and enter /usr/bin/ruby -e \"$(curl -fsSL https:/raw.githubusercontent.com/Homebrew/install/master/install)\"\nEnter brew install git into the terminal\n\n\n\nFinal Git set up steps\nNow that you have Git running, you need to tell it who you are. This allows multiple people to make changes to code, and the correct names will be attached to the changes.\nOpen up the Git Bash and enter\ngit config --global user.name 'Firstname Lastname'\ngit config --global user.email 'my_email@gmail.com'\nTyping in git config --global --list is a way to check that your details have been saved correctly.\nNote: it is essential that you enter the same email as your GitHub account information. This way you can connect the two. If you would prefer to use a different user name than your GitHub user name you can. This would help show you which computer you completed the work on, but it is not important to most people.\n\n\nInstallation problems\nIf you followed the instructions above, Git should be ready to go. However, sometimes you still end up with errors. This is far more likely with Windows that Mac, but if you find that the next steps don’t work for you, see if the other installation options from Jenny Bryan’s book here work for you, or the trouble shooting tips here (and here if you’re on Windows), which are useful when trying to connect Git with RStudio."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#git-client",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#git-client",
    "title": "An Introduction to Reproducible Research",
    "section": "Git client",
    "text": "Git client\nNow you have Git installed, there are a number of ways to use it. The easiest way is to use a client, which allows you to use buttons instead of typing code. They also provide a visual for more complicated ideas, such as branching, greatly simplifying the process. I prefer to use the GitKraken client, and they’re associated GloBoards for project To-Do’s, but you can use others. SourceTree is another good alternative, but I have had some issues connecting to some GitHub accounts, so I have since moved away from it."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#remote-repositories",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#remote-repositories",
    "title": "An Introduction to Reproducible Research",
    "section": "Remote repositories",
    "text": "Remote repositories\nIt is not essential, but one of the best things about Git is that online repositories create an easier way to sync your work between computers and colleagues, avoiding much of the mess caused when this work happens simultaneously / your file sharing system of choice isn’t syncing properly. In this section, I will explain the correct way to utilize this, and the other way …\n\nGitHub - the Good\nGitHub is built for this. You should take full advantage of the effort and troubleshooting that has gone into the platform. Don’t try and recreate the wheel\nWith GitHub now offering unlimited free private repositories, I would recommend that you set up an account with GitHub. The reason why I suggest GitHub over a different purpose-built platform (such as Bitbucket or GitLab) is the community. Previously, I would have recommended Bitbucket due to the unlimited free private repositories, but this is no longer a restriction with GitHub. With GitHub, if you ever want to make your code open-source, you immediately have access to the largest community of programmers who can help you improve your code, as well as putting it to good use. And isn’t that why we do research?\nNow that you’ve decided to use GitHub, it’s very easy to register. Just click the link above and select the package you’d like. If you have an academic email address, consider making this your primary email address on the account, as it gives you a PRO account unlimited collaborators on private repositories, unlike the standard account that limits it to 3 collaborators.\nBe sure to choose a user name that is easy to remember, and easy to find. I would suggest just using your name.\nNow you have a GitHub account set up, this is your remote. If you work on a project with collaborators, this can be shared with them. That way, collaborators can work on their own versions of the code on their local machine (computer), and when it’s ready for other people to use/help write, they can push it to the remote where others can access it. Don’t worry if you don’t know what push is - we’ll cover that soon.\n\n\nPrivate server\nIt is possible to use and get the benefits of Git without a purpose-made online repository such as GitHub, but it’s not as simple and it’s not as stable. Because services like Dropbox and OneDrive are not built for storing and tracking changes in code and dot files, it can go wrong, especially when more than one author is involved. Of all the file syncing systems, Dropbox seems to be the best option due to the git-remote-dropbox extension, but this is still inferior to GitHub etc. With these home-made systems, corruption of the project repository is a matter of “when”, not “if”. If you insist on using this option, go read the git basic commands first, come back, and read on …\n\nDropbox - the Bad\n\ngit-remote-dropbox\nInstall the git-remote-dropbox extension. The instructions were copied from the documentation and *have not been tested*.\n\nInstall the helper with pip install git-remote-dropbox.\nGenerate an OAuth 2 token by going to the app console, creating a Dropbox API app with “Full Dropbox” access (or “App folder” access if you prefer, if you’re not going to be using Dropbox’s sharing features to use git-remote-dropbox in a multi-user setup), and generating an access token for yourself.\nSave your OAuth token in ~/.config/git/git-remote-dropbox.json or ~/.git-remote-dropbox.json. The file should look something like this:\n\n{\n    \"default\": \"xxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxx\"\n}\n\ngit-remote-dropbox supports using multiple Dropbox accounts. You can create OAuth tokens for different accounts and add them all to the config file, using a user-defined username as the key:\n\n{\n    \"alice\": \"xxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxx\",\n    \"ben\": \"xxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxx\",\n    \"charlie\": \"xxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxx\"\n}\n\nYou can tell git-remote-dropbox to use the token corresponding to username by specifying a URL like dropbox://username@/path/to/repo.\nYou can also specify the token inline by using a URL like dropbox://:token@/path/to/repo.\n\n\n\nCreating a Dropbox repository\nNow you’ve installed the helper extension, you can start using Dropbox for your remote repositories. Unless a project already exists with a Dropbox repository (i.e. you’ve been added to the project and were not the one to set it up), I would recommend that you first create the repositories on your local machine using the steps below.\n\nCreate a project folder on your computer (not in your Dropbox folder), and open up the Git Bash within the folder\nEnter git init to initialize your folder as a Git repository\nEnter git remote add origin \"dropbox:///path/to/repo\"\n\nIf a repository already exists in a Dropbox folder, and you want to make a local copy, you can do the following:\n\nCreate a project folder on your computer, and open up the Git Bash within the folder\nEnter git clone \"dropbox:///path/to/repo\" -b master\n\nYou are now set up to use Dropbox as your remote repository and can commit, push, and pull changes using the Git Bash commands:\n\ngit add . This stages the changes to your files, and it is essential to do before you commit\ngit commit -m \"your commit message\"\ngit push origin master\ngit pull origin master\n\n\n\n\nOneDrive/Google Drive/Network Drive/others - the Ugly\n*The instructions for this are based off the following articles and have not been tested*.\nhttps://blog.geekforbrains.com/how-to-use-dropbox-and-git-for-private-repos-e1d304d5ff79\nhttp://autchen.github.io/guides/2016/03/10/git-onedrive.html\nhttp://tony.halcyonlane.com/blog/2011/09/22/Using-git-at-work-on-a-Windows-network-drive//\nhttps://medium.com/@techstreams/git-google-drive-simple-git-host-3a84db4fc1fd\nIf you want to use a different file syncing system, then you need to create a bare remote repository. This is structured differently than a normal git repository, which makes it slightly better for use as a remote repository … but it’s still a bad idea and can corrupt the project.\n\nCreate/open an existing project folder on your computer (not in your OneDrive folder), and open up the Git Bash within the folder\nEnter git init to initialize your folder as a Git repository\nAssuming you have files already in the directory, you should commit them using\n\ngit add --all\ngit commit -m \"your commit message\"\n\nCreate the bare repo in OneDrive etc using\n\ngit init --bare . ~/OneDrive///path/to/repo/project.git\n\nConfigure your remote using\n\ngit remote add origin ~/OneDrive///path/to/repo/project.git\n\npush/pull your commits using\n\ngit push origin master\n\n\nYou can share the OneDrive repository (folder) so that multiple people can work on the project. However, if you do this, it is essential you coordinate your push/pull commands to avoid corrupting the repository."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#creating-a-repository",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#creating-a-repository",
    "title": "An Introduction to Reproducible Research",
    "section": "Creating a repository",
    "text": "Creating a repository\nIf everything has gone well until now, you’re ready to create a project repository. This is where all your code, all your data, all your output files, everything, should live. Whilst you can create a repository directly on your computer, I would advise against this as it causes additional headaches when you want to connect it with GitHub. Instead, create the remote repository first on GitHub.\n\nGo to www.github.com and click the + and “New repository”.\nChoose a project name\nDecide whether you want it to be a public or private project (choose private if working on sensitive data and research, as you can always convert it to public later)\nInitialize with a README file\n\n\nConnecting to GitHub\nIf you are using SourceTree, there are two ways to connect your computer to your GitHub repositories. I would recommend the first option, as it makes cloning repositories (making a copy on your local computer) easier in the future, as you don’t have to go to GitHub each time to find the HTTPS/SSH address. The methods for GitKraken are essentially the same, and SourceTree seems to be slightly more popular, hence why I describe it here.\nMethod 1\n\nGo to Tools -> Options -> Authentication in SourceTree and add your GitHub account details\nLeave the preferred protocol at “HTTPS” for the moment, unless you know what you’re doing with SSH keys\nNow open a new tab, click on Remote, and you should see your repositories listed\nClone the repositories that you’d like to work on\n\n\nNote: Now SourceTree and GitHub are connected, you shouldn’t have to do the first few steps - just go to step 3.\n\nMethod 2\n\nGo to your repository on GitHub and click on the green “Clone or download” button\nCopy the HTTPS address (your settings should say “Clone with HTTPS” above it, otherwise click “Use HTTPS”)\nGo to SourceTree, open a new tab, and click on “Clone”\nPaste the HTTPS address into the “Source Path / URL:” box\nClick on the “Clone” button at the bottom\n\nMethod 3 (not recommended)\nIf you would like to do it the hard way and use the Git Bash, read the instructions here\nNote: if you would like to use SSH keys, read the instructions here"
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#basic-commands",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#basic-commands",
    "title": "An Introduction to Reproducible Research",
    "section": "Basic commands",
    "text": "Basic commands\nThere are many commands that you could learn in Git, but these are the basics, and will be sufficient for pretty much everything you’ll need to do at the moment.\n\ncommit: this standings for committing a change to your file in Git. Think of it as saving a document, but instead of saving the whole document as-is, Git saves just the changes since the last version. This makes it very efficient, especially when it comes to backing up your work. Key points:\n\ncommit often. By making and saving small changes, your code versions becomes more readable in case you need to go back and find out exactly what and where it went wrong.\nAlways write helpful messages - keep them succinct, but make sure they describe what the change you made was.\n\npull: this commands copies the version of the code from your remote to your local machine. Use this when you want to get the most up-to-date version of your code to work on (assuming your local version isn’t the most up-to-date)\npush: the opposite of pull. If your local version is the most up-to-date version, push your version to the remote."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#branching",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#branching",
    "title": "An Introduction to Reproducible Research",
    "section": "Branching",
    "text": "Branching\nBranching is a key part of the Git work-flow. It allows you to make changes to your code, without worrying about breaking previously ‘good’ code. But what is it?\nSimply put, when you create another branch you are creating a copy of your code at that point in time. This is useful because it allows you to make changes to your copy, and leave your original code intact! So there’s no concern about breaking your working code while you test out some ideas.\n\n\n“But isn’t that why we use Git?”\n\nKind of. But Git is only so powerful. If you have working code, you don’t want to put it out of action whilst you test ideas out, especially if other people need to use your code and can’t wait for you to figure out your future problems. So creating another branch allows you to get around this issue. For most projects, you can get away with just two branches, a master and a develop, which are explained below. If your project is complex, and requires multiple people to work on the code at the same time, it would be worth you looking at implementing this model.\nThe image to the right is copied from the model listed above. It is useful in illustrating the master and develop approach to branching.\n\nCreating a branch\nAs with all things in Git, you can do this multiple ways. I prefer to use the client, as I find it far more intuitive when you can see the changes, but you can use the command line or Git bash. If you want to explore the command line code, I would recommend visiting this website, which allows you to interact with the code through illustrations.\nWhen you are in your client (in this case, SourceTree), open the repository you would like to create a branch in. You will notice that there are two buttons called Branch and Merge. If you click on Branch, you will see something like this\n\nEnter the branch name you would like to create into New Branch (I would suggest develop), and hit Create Branch. That’s it. You now have a master and develop branch.\nYou might notice the tick-box Checkout New Branch. This means SourceTree will execute the command git checkout develop i.e. you will move to the develop branch to continue your work. Now, any changes you make to your code will happen in the develop copy of the code, not in your master branch. Neat. If you want to move back to master branch at some point, you simply right click on the master branch on the left side of SourceTree, and select Checkout master....\n\n\nMerging a branch\nYou’ve created a develop branch so you can keep you master pristine and in working condition. But now you’ve made changes you’re happy with, and you want to incorporate them in the main code. To do this, you need to merge the changes from develop into master.\nTo do this, first you need to checkout the master branch, so you are merging changes into it. Then, click on the Merge button in SourceTree. Select the commit you would like to merge into the master branch (most likely the top one in the develop branch), and click OK. You should have a view like this.\n\nYou have now merged your first feature. Whilst the merge feature is particularly useful, it is not the only way of doing this. rebase is another option that works in a slightly different way. It is slightly beyond the scope of this document, but you should read this document and visit this website, as suggested previously, to get experience of putting them both into practice."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#git-and-jupyter",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#git-and-jupyter",
    "title": "An Introduction to Reproducible Research",
    "section": "Git and Jupyter",
    "text": "Git and Jupyter\nUnfortunately, Git and Jupyter don’t always play nicely, so we have to do a few things to try and get around the issues. Due to the way the notebooks create and store the outputs from the code, diffs become unreadable. There are a few ways to get around this. The first option is the simplest, but the others provide a little more control over what you see in the diffs. This is here to serve as an introduction to the tools, but not as a tutorial, so only the links to the documentation have been provided for you to read.\n\nClear all outputs before you save and commit the files. That way, Git only tracks changes to the input\nDownload the notebook as a markdown file allowing diffs to be tracked in Git as normal\nnbdime\nReviewNB\nNextjournal is a promising take on notebooks that simplifies the process of making reproducible research. Currently it is only in beta, and for private research, but if it has a free version when it becomes established it would be a good option allowing a ‘Google Docs’ style of version control."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#project-structure",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#project-structure",
    "title": "An Introduction to Reproducible Research",
    "section": "Project structure",
    "text": "Project structure\nhttps://nicercode.github.io/blog/2013-04-05-projects/\nhttps://tomwallis.info/2014/01/16/setting-up-a-project-directory/\n\nThese two resources describe the project structure that I advocate for in a little more detail, with a few minor differences. If you work in R I would recommend that you follow nicercode’s other suggestions as well, particularly regarding the creation of an R project.\n\nhttps://medium.freecodecamp.org/why-you-need-python-environments-and-how-to-manage-them-with-conda-85f155f4353c\n\nThis takes a deeper look into how to manage python environments with anaconda, and how this affects your project structures. This is useful if you are work with python 2.x and python 3.x, but also allows your to ensure old code won’t get broken when modules are updated as each module is specific to the environment it is downloaded in."
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#git-1",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html#git-1",
    "title": "An Introduction to Reproducible Research",
    "section": "Git",
    "text": "Git\nhttps://happygitwithr.com/\n\nI cannot emphasise this enough: this is genuinely the best resource I have come across for explaining how to set up and organise a project with Git. Whilst it is aimed at R users, there is a large amount of cross-over, so read it regardless of the language you use.\n\nhttps://medium.freecodecamp.org/how-not-to-be-afraid-of-git-anymore-fe1da7415286\n\nThis helps you understand the nuts-and-bolts of Git by learning to use the command line, rather than an application like SourceTree.\n\nhttps://git-scm.com/book/en/v2/\n\nThe literal book on Git. Everything from the basics to the advanced.\n\nhttps://nvie.com/posts/a-successful-git-branching-model/\n\nIf you feel comfortable with the idea of branching and are interested in a good extension of what we’ve covered, this will help. Roughly speaking, the more complex you project is and the more people that are involved simultaneously, the more branches you want so you can handle problems as they come up, without breaking previously ‘good’ code."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "A longitudinal cohort study, comprising of two geographically related cohorts, that aims to examine the effect of Penn State University students on the SARS-CoV-2 incidence in the surrounding community. We have recently published a the interim serological results in Nature Scientific Reports, which can be found here. The second part of the project focuses on relating the differential exposures observed in the student cohort to latent risk profiles, examining the potential impact of interventions to reduce infections.\n\n\n\nAn ongoing collaboration with Médecin Sans Frontières’ (MSF) Epicentre unit to analyze measles seroprevalence in the ex-Katanga region of the Democratic Republic of Congo (DRC). The intial project examined the role of new laboratory testing facilities on the speed of diagnosis and outbreak response decisions. The second project examines the impact of Supplemental Immunization Activities in the ex-Katanga region; principally, characterizing the spatial and age-specific seronegativity, and examining the relationship between optical density (OD) distributions and seropositivity thresholds using finite mixture models."
  },
  {
    "objectID": "projects.html#past-projects",
    "href": "projects.html#past-projects",
    "title": "Projects",
    "section": "Past Projects",
    "text": "Past Projects\n\nWaning Measles Immunity\nA prospective cross-sectional serology study of Canadian newborns and mothers assessing the rate of waning measles, varicella, and mumps antibodies in infants, including subgroup analysis by vaccination status. A retrospective analysis of waning measles antibody titers (PRNT) in stored sera from a separate cohort of Canadian newborns was published as part of the study, and can be found here"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Callum Arnold",
    "section": "About Me",
    "text": "About Me\nI am a PhD Candidate in Biology at Pennsylvania State University, where I build mathematical models of infectious diseases as part of Dr. Matt Ferrari’s lab (within the Center for Infectious Disease Dynamics), in addition to other infectious disease epidemiology work. I previously worked as a clinical research coordinator in the Infectious Disease Division at the Hospital for Sick Children (Toronto, Canada), and concurrently completed an MSc in Global Health Policy at LSHTM. Whilst completing my Masters in computational chemistry, I realized that I enjoyed research and computational modeling, but wanted to work in a more applied healthcare-related field. Since then, I have applied and developed my skills in Public Health research.\nMy research interests are in infectious disease epidemiology, with a particular focus on the use of mathematical models to improve outbreak response and resource utilization. I primarily work with R and Julia, but have experience with Python, Bash, and am learning Stan for Bayesian modeling.\nWhen I’m not working, I can be found outside doing one of the following (depending on the season): mountain biking, road cycling, rock climbing, hiking, snowboarding, cross-country skiing, or very occasionally, running."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Callum Arnold",
    "section": "Education",
    "text": "Education\nPhD Biology, 2020 - Present, Pennsylvania State University\nMSc Global Health Policy, 2017 - 2020, London School of Hygiene and Tropical Medicine\nMChem Chemistry, 2011 - 2015, University of Oxford"
  },
  {
    "objectID": "index.html#research-experience",
    "href": "index.html#research-experience",
    "title": "Callum Arnold",
    "section": "Research Experience",
    "text": "Research Experience\n\nPhD Candidate, Aug 2020 – Present, Pennsylvania State University\nInfectious disease epidemiology and modelling with Dr. Matt Ferrari.\nCurrently working on:\n\nThe Data4Action Research Project examining the dynamics of COVID-19 in a university community\nResource utilisation strategies for measles surveillance and detection in the DRC\nThe effects of population-level thresholds for the detection and response to outbreaks\n\n\n\nClinical Research Coordinator, Apr 2018 – Dec 2019, The Hospital for Sick Children\nCoordinated a multi-centre observational study into waning immunity in infants to measles, mumps and varicella, and managed all data produced by the National Microbiology Laboratory and the Nova Scotia Health Authority laboratory.\nResponsibilities included:\n\nData Management\nData Analysis\nGrant Applications\nPatient enrollment and consent\n\n\n\nHonorary Clinical Researcher, Jun 2016 - May 2019, BOTNAR, University of Oxford\nResponsibilities included:\n\nData Analysis\n4-D CT Analysis\nMRI Segmentation\nContributing researcher in multicentre FAIM study"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "An Introduction to Reproducible Research\n\n\n\n\n\nAn introductorary course on reproducible epidemiology research using Git and notebooks.\n\n\n\n\n\n\nAug 15, 2019\n\n\nCallum Arnold-Leps\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html",
    "href": "posts/2019-08-15-an-introduction-to-reproducible-research/repro-research.html",
    "title": "An Introduction to Reproducible Research",
    "section": "",
    "text": "This book’s focus is on how to produce reproducible research, and should serve as an introduction to data management and project organisation. Through the course of this document, we explain techniques that can be employed easily to help add structure to your research projects and reduce the time spent poring over code to determine if your code really does produce the table and figures you have in your manuscript or poster. Not only does this aid you, but it is essential if the project moves between people. We also hope that the structures we suggest will help you find documents and files more easily.\n\n\nYou can find the bookdown version of this blog post here\nWhilst there are many tools that we can use to ensure our projects and code are tidy and result in reproducible work, some of these may not possible to implement given the potential requirements for administrative privileges during set up. As such, we have divided this book into multiple sections, progressively getting more involved as the book continues. Whilst you may be able to utilise these more sophisticated tools, the core of reproducible research remains the same, so the first chapters still apply.\nWe start by explaining what reproducible research is, why we need it, and how the data we receive can be integrated into a reproducible research workflow. Next, we suggest ways in which you can structure projects to assist this workflow. We end by discussing how to create a Jupyter Notebook and produce the output documents, allowing you to integrate your code and results in a dynamic document.\nWe hope that you enjoy the content and feel like you come away having learnt something useful, and that this book can serve as a reference document for your future research. If you have any questions that cannot be answered within the book, or you would like to contribute and improve this document, please contact us.\nThis document would not be possible without the contributions of Stephanie Hughes from Public Health Ontario, so thank you Steph!"
  }
]